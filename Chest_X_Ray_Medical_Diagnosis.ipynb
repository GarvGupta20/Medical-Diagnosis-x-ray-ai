{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray Medical Diagnosis with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZYK-0rin5x7"
   },
   "source": [
    "<img src=\"xray-header-image.png\" style=\"padding-top: 50px;width: 87%;left: 0px;margin-left: 0px;margin-right: 0px;\">\n",
    "\n",
    "In this notebook we will explore medical image diagnosis by building a state-of-the-art chest X-ray classifier using Keras. \n",
    "\n",
    "In this notebook we will walk through some of the steps of building and evaluating this deep learning classifier model. In particular, we will:\n",
    "- Pre-process and prepare a real-world X-ray dataset\n",
    "- Use transfer learning to retrain a DenseNet model for X-ray image classification\n",
    "- Learn a technique to handle class imbalance\n",
    "- Measure diagnostic performance by computing the AUC (Area Under the Curve) for the ROC (Receiver Operating Characteristic) curve\n",
    "- Visualize model activity using GradCAMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "Use these links to jump to specific sections of this assignment!\n",
    "\n",
    "- [1. Import Packages and Function](#1)\n",
    "- [2. Load the Datasets](#2)\n",
    "    - [2.1 Preventing Data Leakage](#2-1)\n",
    "        - [Exercise 1 - Checking Data Leakage](#Ex-1)\n",
    "    - [2.2 Preparing Images](#2-2)\n",
    "- [3. Model Development](#3)\n",
    "    - [3.1 Addressing Class Imbalance](#3-1)\n",
    "        - [Exercise 2 - Computing Class Frequencies](#Ex-2)\n",
    "        - [Exercise 3 - Weighted Loss](#Ex-3)\n",
    "    - [3.3 DenseNet121](#3-3)\n",
    "- [4. Training [optional]](#4)\n",
    "    - [4.1 Training on the Larger Dataset](#4-1)\n",
    "- [5. Prediction and Evaluation](#5)\n",
    "    - [5.1 ROC Curve and AUROC](#5-1)\n",
    "    - [5.2 Visualizing Learning with GradCAM](#5-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XI8PBrk_2Z4V"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1. Import Packages and FunctionsÂ¶\n",
    "\n",
    "We'll make use of the following packages:\n",
    "- `numpy` and `pandas` is what we'll use to manipulate our data\n",
    "- `matplotlib.pyplot` and `seaborn` will be used to produce plots for visualization\n",
    "- `util` will provide the locally defined utility functions that have been provided for this assignment\n",
    "\n",
    "We will also use several modules from the `keras` framework for building deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SciPy in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from SciPy) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Je3yV0Wnn5x8",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SciPy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSciPy\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SciPy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import SciPy\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PMDCWQRn5yA"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 Load the Datasets\n",
    "\n",
    "For this project, we will be using the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315) which contains 108,948 frontal-view X-ray images of 32,717 unique patients. \n",
    "- Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions. \n",
    "- These in turn can be used by physicians to diagnose 8 different diseases. \n",
    "- We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies. \n",
    "- In other words it will predict 'positive' or 'negative' for each of the pathologies.\n",
    " \n",
    "You can download the entire dataset for free [here](https://nihcc.app.box.com/v/ChestXray-NIHCC). \n",
    "- We have provided a ~1000 image subset of the images for you.\n",
    "- These can be accessed in the folder path stored in the `IMAGE_DIR` variable.\n",
    "\n",
    "The dataset includes a CSV file that provides the labels for each X-ray. \n",
    "\n",
    "To make my job a bit easier, I have processed the labels for our small sample and generated three new files to get you started. These three files are:\n",
    "\n",
    "1. `nih/train-small.csv`: 875 images from our dataset to be used for training.\n",
    "1. `nih/valid-small.csv`: 109 images from our dataset to be used for validation.\n",
    "1. `nih/test.csv`: 420 images from our dataset to be used for testing. \n",
    "\n",
    "This dataset has been annotated by consensus among four different radiologists for 5 of our 14 pathologies:\n",
    "- `Consolidation`\n",
    "- `Edema`\n",
    "- `Effusion`\n",
    "- `Cardiomegaly`\n",
    "- `Atelectasis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidebar on meaning of 'class'\n",
    "It is worth noting that the word **'class'** is used in multiple ways is these discussions. \n",
    "- We sometimes refer to each of the 14 pathological conditions that are labeled in our dataset as a class. \n",
    "- But for each of those pathologies we are attempting to predict whether a certain condition is present (i.e. positive result) or absent (i.e. negative result). \n",
    "    - These two possible labels of 'positive' or 'negative' (or the numerical equivalent of 1 or 0) are also typically referred to as classes. \n",
    "- Moreover, we also use the term in reference to software code 'classes' such as `ImageDataGenerator`.\n",
    "\n",
    "As long as you are aware of all this though, it should not cause you any confusion as the term 'class' is usually clear from the context in which it is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data\n",
    "Let's open these files using the [pandas](https://pandas.pydata.org/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "5JRSHB7i0t_6",
    "outputId": "69830050-af47-4ebc-946d-d411d0cbdf5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>PatientId</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008270_015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00029855_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001297_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00012359_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017951_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0  00008270_015.png            0             0              0      0   \n",
       "1  00029855_001.png            1             0              0      0   \n",
       "2  00001297_000.png            0             0              0      0   \n",
       "3  00012359_002.png            0             0              0      0   \n",
       "4  00017951_001.png            0             0              0      0   \n",
       "\n",
       "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n",
       "0         0          0         0       0             0     0       0   \n",
       "1         1          0         0       0             1     0       0   \n",
       "2         0          0         0       0             0     0       0   \n",
       "3         0          0         0       0             0     0       0   \n",
       "4         0          0         0       0             1     0       0   \n",
       "\n",
       "   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
       "0       8270                   0          0             0  \n",
       "1      29855                   0          0             0  \n",
       "2       1297                   1          0             0  \n",
       "3      12359                   0          0             0  \n",
       "4      17951                   0          0             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"nih/train-small.csv\")\n",
    "valid_df = pd.read_csv(\"nih/valid-small.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"nih/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrDoMlsun5yE"
   },
   "outputs": [],
   "source": [
    "labels = ['Cardiomegaly', \n",
    "          'Emphysema', \n",
    "          'Effusion', \n",
    "          'Hernia', \n",
    "          'Infiltration', \n",
    "          'Mass', \n",
    "          'Nodule', \n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening', \n",
    "          'Pneumonia', \n",
    "          'Fibrosis', \n",
    "          'Edema', \n",
    "          'Consolidation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data count :\n",
      "There are 20 samples of disease Cardiomegaly.\n",
      "There are 13 samples of disease Emphysema.\n",
      "There are 128 samples of disease Effusion.\n",
      "There are 2 samples of disease Hernia.\n",
      "There are 175 samples of disease Infiltration.\n",
      "There are 45 samples of disease Mass.\n",
      "There are 54 samples of disease Nodule.\n",
      "There are 106 samples of disease Atelectasis.\n",
      "There are 38 samples of disease Pneumothorax.\n",
      "There are 21 samples of disease Pleural_Thickening.\n",
      "There are 10 samples of disease Pneumonia.\n",
      "There are 14 samples of disease Fibrosis.\n",
      "There are 16 samples of disease Edema.\n",
      "There are 33 samples of disease Consolidation.\n",
      "There are 675 samples of disease.\n",
      "There are 325 samples of no disease.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample data count :\")\n",
    "count = 0\n",
    "for label in labels:\n",
    "    count += train_df[label].value_counts()[1]\n",
    "    print(f\"There are {train_df[label].value_counts()[1]} samples of disease {label}.\")\n",
    "\n",
    "print(f\"There are {count} samples of disease.\")\n",
    "noData = len(train_df[\"PatientId\"]) - count\n",
    "print(f\"There are {noData} samples of no disease.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKwFwpHLn5yG"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 Preventing Data Leakage\n",
    "It is worth noting that our dataset contains multiple images for each patient. This could be the case, for example, when a patient has taken multiple X-ray images at different times during their hospital visits. In our data splitting, we have ensured that the split is done on the patient level so that there is no data \"leakage\" between the train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Ex-1'></a>\n",
    "#### Checking Data Leakage\n",
    "In the cell below, write a function to check whether there is leakage between two datasets. We'll use this to make sure there are no patients in the test set that are also present in either the train or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jz6dwTSrUcKc"
   },
   "outputs": [],
   "source": [
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "    \n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "    #Converting datalist into frame to get unique patient IDs\n",
    "    df1_patients_unique = set(df1[patient_col])\n",
    "    df2_patients_unique = set(df2[patient_col])\n",
    "    \n",
    "    #Finding the intersection of both sets to check for leakage\n",
    "    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = True if len(patients_in_both_groups) > 0 else False  # boolean (true if there is at least 1 patient in both groups)\n",
    "    \n",
    "    return leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "Rh2p1krrV1g5",
    "outputId": "9ee44d93-8ef1-4c98-f9fa-65b309b9b889",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case 1\n",
      "df1\n",
      "   patient_id\n",
      "0           0\n",
      "1           1\n",
      "2           2\n",
      "df2\n",
      "   patient_id\n",
      "0           2\n",
      "1           3\n",
      "2           4\n",
      "leakage output: True\n",
      "-------------------------------------\n",
      "test case 2\n",
      "df1:\n",
      "   patient_id\n",
      "0           0\n",
      "1           1\n",
      "2           2\n",
      "df2:\n",
      "   patient_id\n",
      "0           3\n",
      "1           4\n",
      "2           5\n",
      "leakage output: False\n"
     ]
    }
   ],
   "source": [
    "# test for check_for_leakage()\n",
    "print(\"test case 1\")\n",
    "df1 = pd.DataFrame({'patient_id': [0, 1, 2]})\n",
    "df2 = pd.DataFrame({'patient_id': [2, 3, 4]})\n",
    "print(\"df1\")\n",
    "print(df1)\n",
    "print(\"df2\")\n",
    "print(df2)\n",
    "print(f\"leakage output: {check_for_leakage(df1, df2, 'patient_id')}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"test case 2\")\n",
    "df1 = pd.DataFrame({'patient_id': [0, 1, 2]})\n",
    "df2 = pd.DataFrame({'patient_id': [3, 4, 5]})\n",
    "print(\"df1:\")\n",
    "print(df1)\n",
    "print(\"df2:\")\n",
    "print(df2)\n",
    "\n",
    "print(f\"leakage output: {check_for_leakage(df1, df2, 'patient_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCWkiLudW_Il"
   },
   "source": [
    "The next cell is run to check if there are patients in both train and test or in both valid and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AMF3Wd3yW-RS",
    "outputId": "e417c9ea-c06b-49a7-af35-d802bc1725eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leakage between train and test: False\n",
      "leakage between valid and test: False\n"
     ]
    }
   ],
   "source": [
    "print(\"leakage between train and test: {}\".format(check_for_leakage(train_df, test_df, 'PatientId')))\n",
    "print(\"leakage between valid and test: {}\".format(check_for_leakage(valid_df, test_df, 'PatientId')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRUvYHpYXhlQ"
   },
   "source": [
    "If we get `False` for both, then we're ready to start preparing the datasets for training. Remember to always check for data leakage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBWZ5l4ln5yH"
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 Preparing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPjuZHPpn5yH"
   },
   "source": [
    "With our dataset splits ready, we can now proceed with setting up our model to consume them. \n",
    "- For this we will use the off-the-shelf [ImageDataGenerator](https://keras.io/preprocessing/image/) class from the Keras framework, which allows us to build a \"generator\" for images specified in a dataframe. \n",
    "- This class also provides support for basic data augmentation such as random horizontal flipping of images.\n",
    "- We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1. \n",
    "    - This will facilitate model training by standardizing the input distribution. \n",
    "- The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\n",
    "    - We will want this because the pre-trained model that we'll use requires three-channel inputs.\n",
    "\n",
    "I have implemented the following using the generator: \n",
    "1. Normalize the mean and standard deviation of the data\n",
    "3. Shuffle the input after each epoch.\n",
    "4. Set the image size to be 320px by 320px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAgVGOAju8pX"
   },
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    \"\"\"\n",
    "    Return generator for training set, normalizing using batch\n",
    "    statistics.\n",
    "\n",
    "    Args:\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        train_generator (DataFrameIterator): iterator over training set\n",
    "    \"\"\"        \n",
    "    print(\"getting train generator...\") \n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization= True)\n",
    "    \n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpRXR-3_u7cl"
   },
   "source": [
    "#### Build a separate generator for valid and test sets\n",
    "\n",
    "Now we need to build a new generator for validation and testing data. \n",
    "\n",
    "**Why can't we use the same generator as for the training data?**\n",
    "\n",
    "Look back at the generator we wrote for the training data. \n",
    "- It normalizes each image **per batch**, meaning that it uses batch statistics. \n",
    "- We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time). \n",
    "- Knowing the average per batch of test data would effectively give our model an advantage.  \n",
    "    - The model should not have any information about the test data.\n",
    "\n",
    "What we need to do is normalize incoming test data using the statistics **computed from the training set**. \n",
    "* We implement this in the function below. \n",
    "* There is one technical note. Ideally, we would want to compute our sample mean and standard deviation using the entire training set. \n",
    "* However, since this is extremely large, that would be very time consuming. \n",
    "* In the interest of time, we'll take a random sample of the dataset and calcualte the sample mean and sample standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtWEAfAnrhMq"
   },
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    \"\"\"\n",
    "    Return generator for validation set and test test set using \n",
    "    normalization statistics from training set.\n",
    "\n",
    "    Args:\n",
    "      valid_df (dataframe): dataframe specifying validation data.\n",
    "      test_df (dataframe): dataframe specifying test data.\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      sample_size (int): size of sample to use for normalization statistics.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
    "    \"\"\"\n",
    "    print(\"getting train and valid generators...\")\n",
    "    # get generator to sample dataset\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=IMAGE_DIR, \n",
    "        x_col=\"Image\", \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga4RZN5On5yL"
   },
   "source": [
    "With our generator function ready, let's make one generator for our training data and one each of our test and  validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from scipy) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "rNE3HWRbn5yL",
    "outputId": "4c6b1c25-a33d-42e0-f442-40971ca52a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train generator...\n",
      "Found 1000 validated image filenames.\n",
      "getting train and valid generators...\n",
      "Found 1000 validated image filenames.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m IMAGE_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnih/images-small/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m get_train_generator(train_df, IMAGE_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels)\n\u001b[1;32m----> 3\u001b[0m valid_generator, test_generator\u001b[38;5;241m=\u001b[39m \u001b[43mget_test_and_valid_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMAGE_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 35\u001b[0m, in \u001b[0;36mget_test_and_valid_generator\u001b[1;34m(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size, batch_size, seed, target_w, target_h)\u001b[0m\n\u001b[0;32m     24\u001b[0m raw_train_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m     25\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mtrain_df, \n\u001b[0;32m     26\u001b[0m     directory\u001b[38;5;241m=\u001b[39mIMAGE_DIR, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m     32\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(target_w, target_h))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# get data sample\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mraw_train_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m data_sample \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# use sample to fit mean and std for test set generator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:384\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator:\n\u001b[0;32m    383\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 384\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    386\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:2012\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2010\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2012\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2029\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   2030\u001b[0m         x,\n\u001b[0;32m   2031\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2032\u001b[0m         img_channel_axis,\n\u001b[0;32m   2033\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:2526\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.apply_affine_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_affine_transform\u001b[39m(\n\u001b[0;32m   2484\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2496\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   2497\u001b[0m ):\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies an affine transformation specified by the parameters given.\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \n\u001b[0;32m   2500\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;124;03m        ImportError: if SciPy is not available.\u001b[39;00m\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscipy\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage transformations require SciPy. Install SciPy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2529\u001b[0m     \u001b[38;5;66;03m# Input sanity checks:\u001b[39;00m\n\u001b[0;32m   2530\u001b[0m     \u001b[38;5;66;03m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001b[39;00m\n\u001b[0;32m   2531\u001b[0m     \u001b[38;5;66;03m# 2. channels must be either first or last dimension\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = \"nih/images-small/\"\n",
    "train_generator = get_train_generator(train_df, IMAGE_DIR, \"Image\", labels)\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"Image\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYtXacDgn5yN"
   },
   "source": [
    "Let's peek into what the generator gives our model during training and validation. We can do this by calling the `__get_item__(index)` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "Jh77vpN-n5yO",
    "outputId": "c4e68e79-e8f2-4bb9-8909-072c9dd2f805"
   },
   "outputs": [],
   "source": [
    "x, y = train_generator.__getitem__(0)\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WBMpRxcDMgp"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 Model Development\n",
    "\n",
    "Now we'll move on to model training and development. We have a few practical challenges to deal with before actually training a neural network, though. The first is class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHBSgvxfn5yR"
   },
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 Addressing Class Imbalance\n",
    "One of the challenges with working with medical diagnostic datasets is the large class imbalance present in such datasets. Let's plot the frequency of each of the labels in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "-OvyPe5en5yR",
    "outputId": "077747ad-7ab8-463d-8335-6b243cb29e63"
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(train_generator.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this plot that the prevalance of positive cases varies significantly across the different pathologies. (These trends mirror the ones in the full dataset as well.) \n",
    "* The `Hernia` pathology has the greatest imbalance with the proportion of positive training cases being about 0.2%. \n",
    "* But even the `Infiltration` pathology, which has the least amount of imbalance, has only 17.5% of the training cases labelled positive.\n",
    "\n",
    "Ideally, we would train our model using an evenly balanced dataset so that the positive and negative training cases would contribute equally to the loss. \n",
    "\n",
    "If we use a normal cross-entropy loss function with a highly unbalanced dataset, as we are seeing here, then the algorithm will be incentivized to prioritize the majority class (i.e negative in our case), since it contributes more to the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nHRd9p9n5yU"
   },
   "source": [
    "#### Impact of class imbalance on loss function\n",
    "\n",
    "Let's take a closer look at this. Assume we would have used a normal cross-entropy loss for each pathology. We recall that the cross-entropy loss contribution from the $i^{th}$ training data case is:\n",
    "\n",
    "$$\\mathcal{L}_{cross-entropy}(x_i) = -(y_i \\log(f(x_i)) + (1-y_i) \\log(1-f(x_i))),$$\n",
    "\n",
    "where $x_i$ and $y_i$ are the input features and the label, and $f(x_i)$ is the output of the model, i.e. the probability that it is positive. \n",
    "\n",
    "Note that for any training case, either $y_i=0$ or else $(1-y_i)=0$, so only one of these terms contributes to the loss (the other term is multiplied by zero, and becomes zero). \n",
    "\n",
    "We can rewrite the overall average cross-entropy loss over the entire training set $\\mathcal{D}$ of size $N$ as follows: \n",
    "\n",
    "$$\\mathcal{L}_{cross-entropy}(\\mathcal{D}) = - \\frac{1}{N}\\big( \\sum_{\\text{positive examples}} \\log (f(x_i)) + \\sum_{\\text{negative examples}} \\log(1-f(x_i)) \\big).$$\n",
    "\n",
    "Using this formulation, we can see that if there is a large imbalance with very few positive training cases, for example, then the loss will be dominated by the negative class. Summing the contribution over all the training cases for each class (i.e. pathological condition), we see that the contribution of each class (i.e. positive or negative) is: \n",
    "\n",
    "$$freq_{p} = \\frac{\\text{number of positive examples}}{N} $$\n",
    "\n",
    "$$\\text{and}$$\n",
    "\n",
    "$$freq_{n} = \\frac{\\text{number of negative examples}}{N}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Ex-2'></a>\n",
    "### Computing Class Frequencies\n",
    "The function below calculates the frequences for each label in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpDGeY2cChYD"
   },
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "    \"\"\"\n",
    "    Compute positive and negative frequences for each class.\n",
    "\n",
    "    Args:\n",
    "        labels (np.array): matrix of labels, size (num_examples, num_classes)\n",
    "    Returns:\n",
    "        positive_frequencies (np.array): array of positive frequences for each\n",
    "                                         class, size (num_classes)\n",
    "        negative_frequencies (np.array): array of negative frequences for each\n",
    "                                         class, size (num_classes)\n",
    "    \"\"\"    \n",
    "    # total number of patients (rows)\n",
    "    N = labels.shape[0]\n",
    "    \n",
    "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "\n",
    "    return positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "BqidQvCaD_xi",
    "outputId": "56a5905a-e61b-47a8-f444-aa89d7481c44"
   },
   "outputs": [],
   "source": [
    "# Test compute_class_freqs()\n",
    "labels_matrix = np.array(\n",
    "    [[1, 0, 0],\n",
    "     [0, 1, 1],\n",
    "     [1, 0, 1],\n",
    "     [1, 1, 1],\n",
    "     [1, 0, 1]]\n",
    ")\n",
    "print(\"labels:\")\n",
    "\n",
    "test_pos_freqs, test_neg_freqs = compute_class_freqs(labels_matrix)\n",
    "\n",
    "print(f\"pos freqs: {test_pos_freqs}\")\n",
    "\n",
    "print(f\"neg freqs: {test_neg_freqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iye-sQoOFG37"
   },
   "source": [
    "Now we'll compute frequencies for our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoxM5jQ0E30D"
   },
   "outputs": [],
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\n",
    "freq_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsJIDPTZn5yW"
   },
   "source": [
    "Let's visualize these two contribution ratios next to each other for each of the pathologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "IqnNCu4In5yW",
    "outputId": "245f1a6b-b292-4c6d-a583-c6924bc61f31",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uvttCM8n5yY"
   },
   "source": [
    "As we see in the above plot, the contributions of positive cases is significantly lower than that of the negative ones. However, we want the contributions to be equal. One way of doing this is by multiplying each example from each class by a class-specific weight factor, $w_{pos}$ and $w_{neg}$, so that the overall contribution of each class is the same. \n",
    "\n",
    "To have this, we want \n",
    "\n",
    "$$w_{pos} \\times freq_{p} = w_{neg} \\times freq_{n},$$\n",
    "\n",
    "which we can do simply by taking \n",
    "\n",
    "$$w_{pos} = freq_{neg}$$\n",
    "$$w_{neg} = freq_{pos}$$\n",
    "\n",
    "This way, we will be balancing the contribution of positive and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zs3_Rgwwn5yZ"
   },
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygNZmdyun5ya"
   },
   "source": [
    "Let's verify this by graphing the two contributions next to each other again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "LPfSFrxjn5yb",
    "outputId": "a4b6354f-ab39-4623-d44b-90cfd9b28506",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9xgoEkpn5yc"
   },
   "source": [
    "As the above figure shows, by applying these weightings the positive and negative labels within each class would have the same aggregate contribution to the loss function. Now let's implement such a loss function. \n",
    "\n",
    "After computing the weights, our final weighted loss for each training case will be \n",
    "\n",
    "$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Ex-3'></a>\n",
    "### Weighted Loss\n",
    "The `weighted_loss` function below returns a loss function that calculates the weighted loss for each batch. Note that we also want to add a small value, $\\epsilon$, to the predicted values before taking their logs. This is simply to avoid a numerical error that would otherwise occur if the predicted value happens to be zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPIBVAasn5yd"
   },
   "outputs": [],
   "source": [
    "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Return weighted loss function given negative weights and positive weights.\n",
    "\n",
    "    Args:\n",
    "      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n",
    "      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n",
    "    \n",
    "    Returns:\n",
    "      weighted_loss (function): weighted loss function\n",
    "    \"\"\"\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Return weighted loss value. \n",
    "\n",
    "        Args:\n",
    "            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n",
    "            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n",
    "        Returns:\n",
    "            loss (Float): overall scalar loss summed across all classes\n",
    "        \"\"\"\n",
    "        # initialize loss to zero\n",
    "        loss = 0.0\n",
    "        \n",
    "        for i in range(len(pos_weights)):\n",
    "            # for each class, we add average weighted loss for that class \n",
    "            pos_loss = -1 * K.mean(pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon))\n",
    "            neg_loss = -1 * K.mean(neg_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon))\n",
    "            loss += pos_loss + neg_loss            \n",
    "        return loss\n",
    "    \n",
    "        ### END CODE HERE ###\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our function with some simple cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "CFjYda3Wulbm",
    "outputId": "87128f53-7a99-40e2-d09a-6539215879d0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'get_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test get_weighted_loss()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sess \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_session\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sess\u001b[38;5;241m.\u001b[39mas_default() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'get_session'"
     ]
    }
   ],
   "source": [
    "# Test get_weighted_loss()\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    print(\"Test example:\\n\")\n",
    "    y_true = K.constant(np.array(\n",
    "        [[1, 1, 1],\n",
    "         [1, 1, 0],\n",
    "         [0, 1, 0],\n",
    "         [1, 0, 1]]\n",
    "    ))\n",
    "    print(\"y_true:\\n\")\n",
    "    print(y_true.eval())\n",
    "\n",
    "    w_p = np.array([0.25, 0.25, 0.5])\n",
    "    w_n = np.array([0.75, 0.75, 0.5])\n",
    "    print(\"\\nw_p:\\n\")\n",
    "    print(w_p)\n",
    "\n",
    "    print(\"\\nw_n:\\n\")\n",
    "    print(w_n)\n",
    "\n",
    "    y_pred_1 = K.constant(0.7*np.ones(y_true.shape))\n",
    "    print(\"\\ny_pred_1:\\n\")\n",
    "    print(y_pred_1.eval())\n",
    "\n",
    "    y_pred_2 = K.constant(0.3*np.ones(y_true.shape))\n",
    "    print(\"\\ny_pred_2:\\n\")\n",
    "    print(y_pred_2.eval())\n",
    "\n",
    "    # test with a large epsilon in order to catch errors\n",
    "    L = get_weighted_loss(w_p, w_n, epsilon=1)\n",
    "\n",
    "    print(\"\\nIf we weighted them correctly, we expect the two losses to be the same.\")\n",
    "    L1 = L(y_true, y_pred_1).eval()\n",
    "    L2 = L(y_true, y_pred_2).eval()\n",
    "    print(f\"\\nL(y_pred_1)= {L1:.4f}, L(y_pred_2)= {L2:.4f}\")\n",
    "    print(f\"Difference is L1 - L2 = {L1 - L2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDZQMmlgn5yh"
   },
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 DenseNet121\n",
    "\n",
    "Next, we will use a pre-trained [DenseNet121](https://www.kaggle.com/pytorch/densenet121) model which we can load directly from Keras and then add two layers on top of it:\n",
    "1. A `GlobalAveragePooling2D` layer to get the average of the last convolution layers from DenseNet121.\n",
    "2. A `Dense` layer with `sigmoid` activation to get the prediction logits for each of our classes.\n",
    "\n",
    "We can set our custom loss function for the model by specifying the `loss` parameter in the `compile()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "gZlxoCTgn5yi",
    "outputId": "7e12120b-8aab-403c-b5ca-2ff77ef978b1",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create the base pre-trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mDenseNet121\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./nih/densenet.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39moutput\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# add a global spatial average pooling layer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\densenet.py:358\u001b[0m, in \u001b[0;36mDenseNet121\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.densenet.DenseNet121\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.DenseNet121\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m     classifier_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    356\u001b[0m ):\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates the Densenet121 architecture.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDenseNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\densenet.py:340\u001b[0m, in \u001b[0;36mDenseNet\u001b[1;34m(blocks, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    338\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = DenseNet121(weights='./nih/densenet.hdf5', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcwhQdOAn5ym"
   },
   "source": [
    "<a name='4'></a>\n",
    "## 4 Training \n",
    "\n",
    "With our model ready for training, we will use the `model.fit()` function in Keras to train our model. \n",
    "- We are training on a small subset of the dataset (~1%).  \n",
    "- So what we care about at this point is to make sure that the loss on the training set is decreasing.\n",
    "\n",
    "Since training can take a considerable time, for pedagogical purposes I have chosen not to train the model here but rather to load a set of pre-trained weights in the next section which was trained in Colab.\n",
    "\n",
    "Python Code for training the model:\n",
    "\n",
    "```python\n",
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=valid_generator,\n",
    "                              steps_per_epoch=100, \n",
    "                              validation_steps=25, \n",
    "                              epochs = 3)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xB5nsGKrn5yp"
   },
   "source": [
    "<a name='4-1'></a>\n",
    "### 4.1 Training on the Larger Dataset\n",
    "\n",
    "Given that the original dataset is 40GB+ in size and the training process on the full dataset takes a few hours, we have trained the model on a GPU-equipped machine for you and provided the weights file from our model (with a batch size of 32 instead) to be used for the rest of this assignment. \n",
    "\n",
    "The model architecture for our pre-trained model is exactly the same, but we used a few useful Keras \"callbacks\" for this training. Do spend time to read about these callbacks at your leisure as they will be very useful for managing long-running training sessions:\n",
    "\n",
    "1. You can use `ModelCheckpoint` callback to monitor your model's `val_loss` metric and keep a snapshot of your model at the point. \n",
    "2. You can use the `TensorBoard` to use the Tensorflow Tensorboard utility to monitor your runs in real-time. \n",
    "3. You can use the `ReduceLROnPlateau` to slowly decay the learning rate for your model as it stops getting better on a metric such as `val_loss` to fine-tune the model in the final steps of training.\n",
    "4. You can use the `EarlyStopping` callback to stop the training job when your model stops getting better in it's validation loss. You can set a `patience` value which is the number of epochs the model does not improve after which the training is terminated. This callback can also conveniently restore the weights for the best metric at the end of training to your model.\n",
    "\n",
    "You can read about these callbacks and other useful Keras callbacks [here](https://keras.io/callbacks/).\n",
    "\n",
    "Let's load our pre-trained weights into the model now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "887bSajLn5yq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./nih/pretrained_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./nih/pretrained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA90g8n6suRV"
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5 Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kz1BEwOyxFbj"
   },
   "source": [
    "Now that we have a model, let's evaluate it using our test set. We can conveniently use the `predict_generator` function to generate the predictions for the images in our test set.\n",
    "\n",
    "**Note:** The following cell can take about 4 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzNrhtf1w2bI",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_vals \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_generator(test_generator, steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_generator))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_vals = model.predict_generator(test_generator, steps = len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtjCtaGen5yt"
   },
   "source": [
    "<a name='5-1'></a>\n",
    "### 5.1 ROC Curve and AUROC\n",
    "To evaluate my model I use a metric called the AUC (Area Under the Curve) from the ROC ([Receiver Operating Characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)) curve. This is also referred to as the AUROC value.\n",
    "\n",
    "We will use the `util.get_roc_curve()` function which has been provided for you in `util.py`. Look through this function and note the use of the `sklearn` library functions to generate the ROC curves and AUROC values for our model. \n",
    "\n",
    "- [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "- [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "6SLI8FHun5yw",
    "outputId": "4f5cc99c-4e1a-421b-fe2d-637df32d6416",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m auc_rocs \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mget_roc_curve(labels, predicted_vals, test_generator)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWZkl01ruZ7P"
   },
   "source": [
    "You can compare the performance to the AUCs reported in the original ChexNeXt paper in the table below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZUoShw2n5yy"
   },
   "source": [
    "For reference, here's the AUC figure from the ChexNeXt paper which includes AUC values for their model as well as radiologists on this dataset:\n",
    "\n",
    "<img src=\"https://journals.plos.org/plosmedicine/article/figure/image?size=large&id=10.1371/journal.pmed.1002686.t001\" width=\"80%\">\n",
    "\n",
    "This method does take advantage of a few other tricks such as self-training and ensembling as well, which can give a significant boost to the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jzy7fLgFn5yy"
   },
   "source": [
    "For details about the best performing methods and their performance on this dataset, we encourage you to read the following papers:\n",
    "- [CheXNet](https://arxiv.org/abs/1711.05225)\n",
    "- [CheXpert](https://arxiv.org/pdf/1901.07031.pdf)\n",
    "- [ChexNeXt](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5aZAlVbn5yz"
   },
   "source": [
    "<a name='5-2'></a>\n",
    "### 5.2 Visualizing Learning with GradCAM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gu9ExySryY6u"
   },
   "source": [
    "One of the challenges of using deep learning in medicine is that the complex architecture used for neural networks makes them much harder to interpret compared to traditional machine learning models (e.g. linear models). \n",
    "\n",
    "One of the most common approaches aimed at increasing the interpretability of models for computer vision tasks is to use Class Activation Maps (CAM). \n",
    "- Class activation maps are useful for understanding where the model is \"looking\" when classifying an image. \n",
    "\n",
    "In this section we will use a [GradCAM's](https://arxiv.org/abs/1610.02391) technique to produce a heatmap highlighting the important regions in the image for predicting the pathological condition. \n",
    "- This is done by extracting the gradients of each predicted class, flowing into our model's final convolutional layer. Look at the `util.compute_gradcam` which has been provided for you in `util.py` to see how this is done with the Keras framework. \n",
    "\n",
    "It is worth mentioning that GradCAM does not provide a full explanation of the reasoning for each classification probability. \n",
    "- However, it is still a useful tool for \"debugging\" our model and augmenting our prediction so that an expert could validate that a prediction is indeed due to the model focusing on the right regions of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the small training set and setup to look at the 4 classes with the highest performing AUC measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kahoZbJn5yz",
    "outputId": "ade0a4e2-4591-4ba5-ec19-1a3487e3f972",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc_rocs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m IMAGE_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnih/images-small/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# only show the lables with top 4 AUC\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m labels_to_show \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(labels, np\u001b[38;5;241m.\u001b[39margsort(\u001b[43mauc_rocs\u001b[49m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'auc_rocs' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"nih/train-small.csv\")\n",
    "IMAGE_DIR = \"nih/images-small/\"\n",
    "\n",
    "# only show the lables with top 4 AUC\n",
    "labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a few specific images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_gradcam(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00008270_015.png\u001b[39m\u001b[38;5;124m'\u001b[39m, IMAGE_DIR, df, labels, labels_to_show)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "util.compute_gradcam(model, '00008270_015.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JC2zy1Kpn5y1",
    "outputId": "9e38a769-e19d-4143-da41-db7a3173a533"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_gradcam(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00011355_002.png\u001b[39m\u001b[38;5;124m'\u001b[39m, IMAGE_DIR, df, labels, labels_to_show)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "util.compute_gradcam(model, '00011355_002.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCHVaLMQn5y2",
    "outputId": "57246709-2662-4590-9198-a412d2f1eea2",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_gradcam(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00029855_001.png\u001b[39m\u001b[38;5;124m'\u001b[39m, IMAGE_DIR, df, labels, labels_to_show)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "util.compute_gradcam(model, '00029855_001.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGwL8FcFn5y4",
    "outputId": "681fb2de-194c-465e-c989-133f334b8299"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_gradcam(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00005410_000.png\u001b[39m\u001b[38;5;124m'\u001b[39m, IMAGE_DIR, df, labels, labels_to_show)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "util.compute_gradcam(model, '00005410_000.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-2'></a>\n",
    "### With this we complete the Chest X-Ray Medical Diagnosis with Deep Learning Project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "G5aZAlVbn5yz"
   ],
   "include_colab_link": true,
   "name": "C1M2_Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
